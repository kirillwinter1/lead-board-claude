# AI в Lead Board: варианты применения

## Контекст

Lead Board — платформа для управления IT-доставкой поверх Jira. Уже содержит богатые данные: задачи, оценки, время, метрики (DSR, velocity, throughput, forecast accuracy), компетенции команды, отсутствия, RICE-скоринг, историю статусов. Эти данные — отличная основа для AI-фич.

---

## 1. AI Digest (BF6 — уже в бэклоге)

**Что:** LLM-генерируемые дайджесты с выводами и рекомендациями.

**Два типа:**
- **Недельный** — резюме: что закрыто, что в работе, риски, метрики, рекомендации на следующую неделю
- **По закрытию эпика** — план vs факт, DSR, участники, что пошло хорошо / что улучшить

**Данные для промпта:** уже доступны через существующие сервисы (BoardService, TeamMetricsService, UnifiedPlanningService, DataQualityService).

**Ценность:** Тим-лид получает готовый отчёт вместо ручного анализа дашбордов. Особенно полезно для stakeholders, которые не заходят в Lead Board каждый день.

**Сложность реализации:** Средняя. Спецификация BF6 уже готова, нужна интеграция с LLM API (Claude/OpenAI).

---

## 2. AI-помощник в оценке задач (Smart Estimation)

**Проблема:** Оценка задач субъективна. Разные разработчики дают разные оценки. Исторические данные о точности оценок не используются при создании новых.

**Что:** AI анализирует завершённые задачи и подсказывает оценку для новых.

**Как работает:**
1. При создании оценки для subtask — AI смотрит на похожие завершённые subtasks (по типу, роли, team, описанию)
2. Сравнивает original estimate vs time spent по похожим задачам
3. Предлагает скорректированную оценку: «Похожие задачи занимали 12-16ч, ваша оценка 8ч — исторически такие оценки были занижены на 40%»
4. В Planning Poker — AI показывает «рекомендацию» как один из участников

**Данные:** `jira_issues` (original_estimate, time_spent, summary, issue_type), `status_changelog` (фактическая длительность фаз), DSR по исполнителю.

**Два подхода:**
- **Без LLM (ML/статистика):** Кластеризация задач по размеру и типу, расчёт коэффициентов отклонения. Дёшево, быстро, детерминированно.
- **С LLM:** Анализ текстового описания задачи для поиска семантически похожих завершённых задач. Точнее, но дороже.

**Ценность:** Повышение точности оценок → более точный forecast → более реалистичные сроки для заказчика.

**Сложность:** Средняя (статистика) / Высокая (LLM с embeddings).

---

## 3. Предсказание рисков срыва сроков (Risk Prediction)

**Проблема:** Сейчас риски видны только когда уже поздно — эпик отстаёт от плана. Нет раннего предупреждения.

**Что:** AI анализирует паттерны и предупреждает заранее: «Эпик X имеет 75% вероятность сдвига на 2+ недели».

**Сигналы для модели:**
- DSR текущих subtasks ниже 1.0 (работа идёт медленнее оценки)
- Исполнитель исторически перерасходует на задачах этого типа
- Зависимости от задач, которые тоже отстают
- Приближающийся отпуск ключевого исполнителя (из absences)
- Незаполненные оценки / низкое quality score
- Частая смена статусов (задача «мечется» между TODO и IN_PROGRESS)
- Время в текущем статусе аномально большое

**Как отображать:**
- На Board/Timeline: цветовой индикатор риска (зелёный / жёлтый / красный)
- На дашборде: топ-5 эпиков с наибольшим риском + объяснение причин
- В Digest: секция «Потенциальные проблемы»

**Подход:** Можно начать с rule-based (набор эвристик, без ML). Позже — обучить простую модель на исторических данных (задачи, которые фактически сорвали сроки vs не сорвали).

**Ценность:** Проактивное управление рисками вместо реактивного.

**Сложность:** Низкая (rule-based) / Высокая (ML-модель).

---

## 4. Аномалии в метриках (Anomaly Detection)

**Проблема:** Метрики есть (DSR, velocity, throughput), но тим-лид должен сам замечать отклонения. При 5+ командах это нереалистично.

**Что:** Система автоматически детектирует значимые отклонения и уведомляет.

**Примеры аномалий:**
- Velocity команды упала на 30% по сравнению со средней за 4 недели
- DSR конкретного разработчика резко ухудшился (был 1.0, стал 0.6)
- Throughput = 0 за неделю (ничего не закрыто)
- Время в статусе «In Review» выросло в 2 раза (bottleneck в code review)
- Один человек залогировал 60ч за неделю (ovework или ошибка логирования)
- Bus factor для критической технологии стал = 1 (из competencies)

**Подход:** Статистический — moving average + стандартное отклонение. Аномалия = значение выходит за 2σ. Не требует ML.

**Где отображать:**
- На дашборде метрик — алерт-панель
- В AI Digest — секция аномалий
- В Notifications (BF7) — push/email

**Ценность:** Раннее обнаружение проблем. Тим-лид не пропускает важные сигналы.

**Сложность:** Низкая.

---

## 5. AI-суммаризация ретроспектив

**Связь с BF23 (Sprint Retrospective).**

**Проблема:** Ретроспектива генерирует 10-20 карточек. После закрытия ретро — сложно быстро понять итоги. Action items есть, но контекст теряется.

**Что:** После фазы Discuss (или при закрытии ретро) — AI генерирует структурированное саммари:
- Главные темы (из группировки и голосов)
- Ключевые проблемы (топ по голосам из колонки «Что улучшить»)
- Позитивные тренды (из «Что хорошо»)
- Связь с метриками («DSR снизился на 15% — команда отметила проблемы с code review»)
- Рекомендации

**Дополнительно:**
- **Тренды между ретро:** AI сравнивает карточки текущего ретро с прошлыми. «Проблема с документацией поднимается 3-е ретро подряд — action items не закрываются.»
- **Предзаполнение карточек:** На основе метрик AI может предложить стартовые карточки: «Velocity выросла на 20% — возможная карточка для "Что хорошо"»

**Ценность:** Institutional memory. Результаты ретро не теряются, тренды видны.

**Сложность:** Средняя.

---

## 6. Умная декомпозиция задач (Task Breakdown Assistant)

**Проблема:** Story без subtask-оценок не может быть запланирована (правило системы). Часто story висят без декомпозиции неделями.

**Что:** AI предлагает набор subtasks для story на основе:
- Описания story из Jira
- Конфигурации pipeline (SA → DEV → QA)
- Исторических паттернов: похожие story обычно имели N subtasks по таким-то ролям
- Шаблонов по типу задачи (Feature → Analysis + Backend Dev + Frontend Dev + QA; Bug → Investigation + Fix + QA)

**Пример вывода:**
```
Story: PROJ-42 «Добавить фильтр по дате на доске»

Предлагаемые subtasks:
1. [SA] Проработать UX и требования — 4ч
2. [DEV] Реализовать backend endpoint фильтрации — 8ч
3. [DEV] Реализовать frontend компонент фильтра — 12ч
4. [QA] Тестирование фильтрации — 4ч

Оценка основана на 5 похожих story (средняя точность оценок: 87%)
```

**Интеграция:** Кнопка «AI Suggest» на карточке story в Board. Предложение можно подтвердить → создаются subtasks в Jira (первый случай записи в Jira из Lead Board — нужно аккуратно).

**Ценность:** Ускорение планирования. Снижение порога входа для новых тим-лидов.

**Сложность:** Высокая (требует write-доступ к Jira + LLM).

---

## 7. Natural Language Query (Чат с данными)

**Проблема:** Чтобы ответить на вопрос «Кто в команде Alpha перегружен на следующей неделе?» — нужно открыть Timeline, посмотреть загрузку по людям, сопоставить с отсутствиями. Это 3-4 клика.

**Что:** Чат-интерфейс, где можно задать вопрос на естественном языке и получить ответ на основе данных Lead Board.

**Примеры запросов:**
- «Какие эпики рискуют не уложиться в срок?»
- «Покажи загрузку команды Backend на следующие 2 недели»
- «Сравни velocity команд Alpha и Beta за последний месяц»
- «Кто из разработчиков свободнее всех на этой неделе?»
- «Сколько задач без оценок в проекте X?»
- «Почему эпик PROJ-100 сдвинулся?»

**Как работает:**
1. LLM получает описание доступных API-endpoints и структуру данных
2. Генерирует вызовы к внутренним API (function calling)
3. Получает данные, формирует ответ на русском

**Альтернатива (проще):** Не полный чат, а «умный поиск» — предложенные вопросы + фиксированные шаблоны запросов.

**Ценность:** Снижение порога входа для менеджеров, которые не хотят разбираться в дашбордах.

**Сложность:** Высокая (function calling, prompt engineering, безопасность).

---

## 8. Оптимизация назначения исполнителей (Smart Assignment)

**Проблема:** Тим-лид вручную назначает людей на задачи. Не всегда учитывает загрузку, компетенции, отсутствия.

**Что:** AI рекомендует оптимального исполнителя для subtask.

**Факторы:**
- **Загрузка** (из UnifiedPlanningService) — кто свободнее
- **Компетенции** (из F40) — кто лучше знает нужную технологию
- **Грейд** (Junior/Middle/Senior) — соответствие сложности задачи
- **Отсутствия** (из F41) — кто будет на месте в нужные даты
- **Исторический DSR** — кто эффективнее на задачах этого типа
- **Bus factor** — назначить на человека с низким bus factor для обучения (опционально)

**Пример:**
```
Subtask: [DEV] Реализовать API endpoint фильтрации
Рекомендация:
  1. Алексей (Senior, загрузка 60%, компетенция Backend: 5/5)
  2. Мария (Middle, загрузка 40%, компетенция Backend: 4/5)
  3. Дмитрий (Junior, загрузка 20%, компетенция Backend: 2/5) — ⚠ для обучения
```

**Подход:** Не требует LLM. Взвешенная формула на основе существующих данных. LLM нужен только если хотим объяснение на естественном языке.

**Ценность:** Более равномерная загрузка, учёт компетенций, снижение bus factor.

**Сложность:** Средняя.

---

## 9. AI-анализ Data Quality с рекомендациями

**Расширение F18 (Data Quality).**

**Сейчас:** 17 автоматических проверок находят проблемы, но не предлагают решение.

**Что добавить:** AI-слой, который:
1. **Приоритизирует** проблемы по влиянию на планирование: «3 эпика без оценок блокируют 40% timeline — это критичнее, чем 10 задач без assignee»
2. **Группирует** проблемы по root cause: «15 задач типа "Bug" не имеют маппинга → это одна проблема в Workflow Config, не 15 отдельных»
3. **Предлагает действия:** «Перейдите в Workflow Config → Issue Types → замапьте "Bug" как STORY»
4. **Тренд:** «Количество проблем Data Quality росло 3 недели подряд. Основной источник — новые типы задач после миграции проекта Y»

**Подход:** Rule-based для приоритизации и группировки. LLM — для генерации текстового объяснения.

**Ценность:** Data Quality из «списка проблем» превращается в actionable advice.

**Сложность:** Низкая-Средняя.

---

## 10. Прогнозирование team velocity (Capacity Forecasting)

**Проблема:** UnifiedPlanningService считает forecast на основе текущей capacity (hoursPerDay × число людей). Но реальная velocity команды зависит от множества факторов, которые не учитываются.

**Что:** Модель предсказывает реальную velocity на следующие N недель с учётом:
- Исторической velocity (тренд за 8-12 недель)
- Запланированных отсутствий (F41)
- Сезонности (праздники, конец квартала)
- Текущего «здоровья» команды (DSR тренд, Data Quality score)
- Количества новичков (Junior < 3 мес в команде = меньший вклад)

**Пример:**
```
Команда Backend (следующие 4 недели):
  Неделя 10: 85ч (сниженная — отпуск Алексея)
  Неделя 11: 95ч (норма)
  Неделя 12: 60ч (23 февраля + 8 марта, сокращённые дни)
  Неделя 13: 100ч (норма)

  Среднее: 85ч vs текущая capacity 100ч → forecast может быть оптимистичен на ~15%
```

**Интеграция:** Результат подаётся в UnifiedPlanningService для более реалистичных прогнозов.

**Подход:** Time series + rule-based корректировки. Не требует LLM.

**Ценность:** Более точный forecast → более реалистичные сроки.

**Сложность:** Средняя.

---

## 11. AutoScore Explainer (Объяснение приоритизации)

**Проблема:** AutoScore состоит из 7-9 факторов. Тим-лид видит число (например, 67), но не всегда понимает, почему именно столько и что изменить для повышения приоритета.

**Сейчас:** Tooltip с breakdown по факторам (уже есть). Но это сухие цифры.

**Что добавить:** AI-объяснение на естественном языке:
- «Эпик PROJ-42 имеет низкий приоритет (32), потому что: нет due date (-25), низкий RICE score, нет прогресса. Для повышения приоритета: установите due date и проведите RICE-оценку.»
- «Эпик PROJ-15 упал в приоритете на 100 пунктов из-за флага. Снимите флаг, чтобы вернуть его в планирование.»

**Подход:** Template-based (без LLM). Набор текстовых шаблонов для каждого фактора. LLM нужен только для естественного языка, но templates достаточно.

**Ценность:** Прозрачность приоритизации для product managers и stakeholders.

**Сложность:** Низкая.

---

## 12. Intelligent Notifications (AI + BF7)

**Связь с BF7 (Notifications).**

**Вместо** простых notification rules (эпик закрыт → уведомление), AI может:
- **Фильтровать шум:** Не слать уведомление о каждом изменении статуса, а агрегировать: «За сегодня команда Backend закрыла 5 задач, 2 эпика продвинулись»
- **Определять важность:** «PROJ-100 был flagged и стоит без движения 3 дня — это блокирует 2 других эпика»
- **Выбирать получателя:** На основе роли и контекста — тим-лиду про загрузку команды, product owner про forecast сдвиги
- **Оптимальное время:** Не будить ночью, агрегировать утренний дайджест

**Подход:** Rule-based с элементами LLM для текста уведомлений.

**Ценность:** Уведомления, которые действительно полезны, а не информационный шум.

**Сложность:** Средняя.

---

## Сводная таблица

| # | Фича | LLM нужен? | Сложность | Ценность | Зависимости |
|---|-------|-----------|-----------|----------|-------------|
| 1 | AI Digest | Да | Средняя | Высокая | Нет (данные есть) |
| 2 | Smart Estimation | Опционально | Средняя | Высокая | Нет |
| 3 | Risk Prediction | Нет (rule-based) | Низкая-Средняя | Высокая | Нет |
| 4 | Anomaly Detection | Нет | Низкая | Средняя | Нет |
| 5 | Ретро суммаризация | Да | Средняя | Средняя | BF23 |
| 6 | Task Breakdown | Да | Высокая | Высокая | Write-доступ к Jira |
| 7 | NL Query (чат) | Да | Высокая | Средняя | Нет |
| 8 | Smart Assignment | Нет | Средняя | Высокая | F40, F41 (уже есть) |
| 9 | Data Quality AI | Опционально | Низкая | Средняя | Нет |
| 10 | Capacity Forecast | Нет | Средняя | Высокая | F41 (уже есть) |
| 11 | AutoScore Explainer | Нет | Низкая | Средняя | Нет |
| 12 | Smart Notifications | Опционально | Средняя | Средняя | BF7 |

---

## Рекомендуемый порядок реализации

### Этап 1: Quick wins (без LLM)
1. **AutoScore Explainer** — шаблоны текстов, минимальные изменения
2. **Anomaly Detection** — статистика по метрикам, алерт-панель
3. **Risk Prediction (rule-based)** — эвристики на существующих данных

### Этап 2: LLM интеграция (базовая)
4. **AI Digest** (BF6) — первый LLM use case, спецификация готова
5. **Data Quality AI** — расширение F18 с LLM-объяснениями

### Этап 3: Продвинутые фичи
6. **Smart Estimation** — historical analysis + LLM для похожих задач
7. **Smart Assignment** — формула на существующих данных
8. **Capacity Forecast** — time series + корректировки

### Этап 4: Тяжёлые фичи
9. **Ретро суммаризация** — после реализации BF23
10. **NL Query** — function calling, prompt engineering
11. **Task Breakdown** — write-доступ к Jira
12. **Smart Notifications** — после BF7

---

## Технические решения

### LLM Provider
Абстракция `LlmProvider` уже спроектирована в BF6. Рекомендуется:
- **Claude API** (Anthropic) как основной провайдер
- **OpenAI** как альтернативный
- Конфигурация через `.env` (API key, model, provider)

### Где считать (LLM vs Rule-based vs ML)?
- **Rule-based:** Risk Prediction, Anomaly Detection, Smart Assignment, AutoScore Explainer — не требуют LLM, работают быстро и предсказуемо
- **LLM:** Digest, NL Query, Task Breakdown, Retro Summary — задачи с естественным языком
- **ML (опционально):** Smart Estimation, Capacity Forecast — если накопится достаточно исторических данных

### Стоимость LLM
Для фич с LLM важно контролировать расход токенов:
- AI Digest: ~1 вызов в неделю на команду → минимальная стоимость
- NL Query: потенциально много вызовов → нужен rate limiting
- Task Breakdown: по запросу → приемлемо
- Рекомендация: начать с Claude Haiku для дешёвых вызовов, Sonnet для качественных
